{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c6088019",
      "metadata": {},
      "source": [
        "# Dataset loading and analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "beb227bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "#importing the necessary libraries\n",
        "import pandas as pd \n",
        "from datasets import load_dataset \n",
        "\n",
        "#loading the dataset using the Hugging Face datasets library\n",
        "df = load_dataset(\"google-research-datasets/go_emotions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4b839024",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': \"My favourite food is anything I didn't have to cook myself.\",\n",
              " 'labels': [27],\n",
              " 'id': 'eebbqej'}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Exploring the training set\n",
        "df['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "21d803e8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'Is this in New Orleans?? I really feel like this is New Orleans.',\n",
              " 'labels': [27],\n",
              " 'id': 'edgurhb'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['validation'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "748485fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "#mapping the labels to the emotion names; \n",
        "# Link to mapping: https://github.com/google-research/google-research/blob/756ae45c4880ad6a01869608250d85a8fb253799/goemotions/data/emotions.txt\n",
        "\n",
        "label_index = {\n",
        "    \"0\": \"admiration\",\n",
        "    \"1\": \"amusement\",\n",
        "    \"2\": \"anger\",\n",
        "    \"3\": \"annoyance\",\n",
        "    \"4\": \"approval\",\n",
        "    \"5\": \"caring\",\n",
        "    \"6\": \"confusion\",\n",
        "    \"7\": \"curiosity\",\n",
        "    \"8\": \"desire\",\n",
        "    \"9\": \"disappointment\",\n",
        "    \"10\": \"disapproval\",\n",
        "    \"11\": \"disgust\",\n",
        "    \"12\": \"embarassment\",\n",
        "    \"13\": \"excitement\",\n",
        "    \"14\": \"fear\",\n",
        "    \"15\": \"gratitude\",\n",
        "    \"16\": \"grief\",\n",
        "    \"17\": \"joy\",\n",
        "    \"18\": \"love\",\n",
        "    \"19\": \"nervousness\",\n",
        "    \"20\": \"optimism\",\n",
        "    \"21\": \"pride\",\n",
        "    \"22\": \"realization\",\n",
        "    \"23\": \"relief\",\n",
        "    \"24\": \"remorse\",\n",
        "    \"25\": \"sadness\",\n",
        "    \"26\": \"surprise\",\n",
        "    \"27\": \"neutral\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "739ae7bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Get the first 1000 rows of the training set, map the labels to the emotion names and store in data_df\n",
        "\n",
        "# Get first 1000 rows from training set\n",
        "train_subset = df['train'].select(range(1000))\n",
        "\n",
        "# Convert to list of dictionaries and map labels to emotion names\n",
        "data_list = []\n",
        "for example in train_subset:\n",
        "    # Map each label (integer) to its emotion name using label_index\n",
        "    emotion_labels_list = [label_index[str(label)] for label in example['labels']]\n",
        "    emotion_labels_string = \", \".join(emotion_labels_list)\n",
        "    data_list.append({\n",
        "        'comment': example['text'],\n",
        "        'emotion labels': emotion_labels_string  # Now contains emotion names instead of numbers\n",
        "    })\n",
        "\n",
        "# Create DataFrame\n",
        "comments_df = pd.DataFrame(data_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "304dd779",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>emotion labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>780</th>\n",
              "      <td>also anxious that people will be angry or surp...</td>\n",
              "      <td>nervousness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>I always just say “thank you” because it’s a n...</td>\n",
              "      <td>admiration, gratitude</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>Define woman please if you're not going to use...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>What are you even talking about? I'm sorry you...</td>\n",
              "      <td>remorse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>I'm scared to even ask my mom ,I might get ye...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>747</th>\n",
              "      <td>I have the same issue with a new co-worker and...</td>\n",
              "      <td>annoyance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>Omg so glad I’m not alone</td>\n",
              "      <td>joy, relief</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>772</th>\n",
              "      <td>I wouldn’t worry, most United fans have never ...</td>\n",
              "      <td>disapproval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>I know you're trying to play devil's advocate ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>That's pretty good all things considered, if t...</td>\n",
              "      <td>admiration, approval, optimism</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               comment  \\\n",
              "780  also anxious that people will be angry or surp...   \n",
              "194  I always just say “thank you” because it’s a n...   \n",
              "174  Define woman please if you're not going to use...   \n",
              "866  What are you even talking about? I'm sorry you...   \n",
              "295   I'm scared to even ask my mom ,I might get ye...   \n",
              "747  I have the same issue with a new co-worker and...   \n",
              "376                          Omg so glad I’m not alone   \n",
              "772  I wouldn’t worry, most United fans have never ...   \n",
              "856  I know you're trying to play devil's advocate ...   \n",
              "519  That's pretty good all things considered, if t...   \n",
              "\n",
              "                     emotion labels  \n",
              "780                     nervousness  \n",
              "194           admiration, gratitude  \n",
              "174                         neutral  \n",
              "866                         remorse  \n",
              "295                            fear  \n",
              "747                       annoyance  \n",
              "376                     joy, relief  \n",
              "772                     disapproval  \n",
              "856                         neutral  \n",
              "519  admiration, approval, optimism  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#print the first 10 rows of the dataframe\n",
        "comments_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cba3442",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a heatmap to visualize model performance (correct vs incorrect predictions)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Function to parse emotion labels from comma-separated string\n",
        "def parse_labels(label_string):\n",
        "    \"\"\"\n",
        "    Parse comma-separated emotion labels into a set of normalized labels.\n",
        "    Handles None, NaN, and empty strings gracefully.\n",
        "    \"\"\"\n",
        "    if pd.isna(label_string) or label_string is None or label_string == '':\n",
        "        return set()\n",
        "    \n",
        "    # Convert to string, split by comma, strip whitespace, convert to lowercase\n",
        "    labels = [label.strip().lower() for label in str(label_string).split(',')]\n",
        "    # Filter out empty strings\n",
        "    labels = [label for label in labels if label]\n",
        "    return set(labels)\n",
        "\n",
        "# Function to check if predicted labels match ground truth labels\n",
        "def labels_match(ground_truth, predicted):\n",
        "    \"\"\"\n",
        "    Compare ground truth and predicted labels.\n",
        "    Returns True if they match exactly (same set of labels).\n",
        "    \"\"\"\n",
        "    gt_set = parse_labels(ground_truth)\n",
        "    pred_set = parse_labels(predicted)\n",
        "    return gt_set == pred_set\n",
        "\n",
        "# Check available columns in comments_df\n",
        "print(\"Available columns in comments_df:\")\n",
        "print(comments_df.columns.tolist())\n",
        "print(\"\\n\")\n",
        "\n",
        "# Identify model columns (exclude 'comment' and 'emotion labels')\n",
        "model_columns = [col for col in comments_df.columns \n",
        "                 if col not in ['comment', 'emotion labels']]\n",
        "\n",
        "print(f\"Found {len(model_columns)} model column(s): {model_columns}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Filter rows that have predictions (non-null values) for at least one model\n",
        "valid_rows = comments_df[model_columns].notna().any(axis=1)\n",
        "df_for_comparison = comments_df[valid_rows].copy()\n",
        "\n",
        "print(f\"Rows with predictions: {len(df_for_comparison)} out of {len(comments_df)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Create a comparison matrix: rows = comment indices, columns = models\n",
        "# Value = 1 (green) if correct, 0 (red) if incorrect\n",
        "comparison_matrix = []\n",
        "\n",
        "for idx, row in df_for_comparison.iterrows():\n",
        "    ground_truth = row['emotion labels']\n",
        "    row_results = []\n",
        "    \n",
        "    for model_col in model_columns:\n",
        "        predicted = row[model_col]\n",
        "        is_correct = labels_match(ground_truth, predicted)\n",
        "        row_results.append(1 if is_correct else 0)\n",
        "    \n",
        "    comparison_matrix.append(row_results)\n",
        "\n",
        "# Convert to numpy array for easier manipulation\n",
        "comparison_array = np.array(comparison_matrix)\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(12, max(8, len(df_for_comparison) * 0.1)))\n",
        "sns.heatmap(comparison_array, \n",
        "            xticklabels=model_columns,\n",
        "            yticklabels=[f\"Comment {i}\" for i in df_for_comparison.index[:50]] if len(df_for_comparison) > 50 else [f\"Comment {i}\" for i in df_for_comparison.index],\n",
        "            cmap=['#ff0000', '#00ff00'],  # Red for incorrect (0), Green for correct (1)\n",
        "            cbar_kws={'label': 'Correct (Green) / Incorrect (Red)'},\n",
        "            vmin=0, vmax=1,\n",
        "            linewidths=0.5,\n",
        "            linecolor='gray')\n",
        "\n",
        "plt.title('Model Performance Heatmap: Correct (Green) vs Incorrect (Red) Predictions', \n",
        "          fontsize=14, fontweight='bold', pad=20)\n",
        "plt.xlabel('Models', fontsize=12, fontweight='bold')\n",
        "plt.ylabel('Comments', fontsize=12, fontweight='bold')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PERFORMANCE SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "for i, model_col in enumerate(model_columns):\n",
        "    correct_count = np.sum(comparison_array[:, i])\n",
        "    total_count = len(comparison_array)\n",
        "    accuracy = (correct_count / total_count) * 100 if total_count > 0 else 0\n",
        "    print(f\"\\n{model_col}:\")\n",
        "    print(f\"  Correct: {correct_count}/{total_count} ({accuracy:.2f}%)\")\n",
        "    print(f\"  Incorrect: {total_count - correct_count}/{total_count} ({100-accuracy:.2f}%)\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1be002c3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "COUNT OF ALL EMOTIONS IN THE DATAFRAME:\n",
            "============================================================\n",
            "admiration: 99\n",
            "amusement: 61\n",
            "anger: 41\n",
            "annoyance: 57\n",
            "approval: 67\n",
            "caring: 21\n",
            "confusion: 33\n",
            "curiosity: 50\n",
            "desire: 13\n",
            "disappointment: 34\n",
            "disapproval: 49\n",
            "disgust: 13\n",
            "embarassment: 6\n",
            "excitement: 13\n",
            "fear: 10\n",
            "gratitude: 63\n",
            "grief: 6\n",
            "joy: 39\n",
            "love: 47\n",
            "nervousness: 3\n",
            "neutral: 336\n",
            "optimism: 29\n",
            "pride: 1\n",
            "realization: 19\n",
            "relief: 2\n",
            "remorse: 9\n",
            "sadness: 32\n",
            "surprise: 35\n",
            "\n",
            "============================================================\n",
            "MISSING EMOTIONS:\n",
            "============================================================\n",
            "All emotions are present at least once.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Count all individual emotions in the dataframe\n",
        "# quick check to see if all emotions are used\n",
        "\n",
        "emotion_counts = {emotion: 0 for emotion in label_index.values()}\n",
        "\n",
        "for emotion_combo in comments_df['emotion labels']:\n",
        "    for emotion in emotion_combo.split(', '):\n",
        "        emotion_counts[emotion] += 1\n",
        "\n",
        "# Print the counts\n",
        "print(\"=\" * 60)\n",
        "print(\"COUNT OF ALL EMOTIONS IN THE DATAFRAME:\")\n",
        "print(\"=\" * 60)\n",
        "for emotion, count in sorted(emotion_counts.items()):\n",
        "    print(f\"{emotion}: {count}\")\n",
        "\n",
        "# (2) Check for missing emotions\n",
        "missing_emotions = [emotion for emotion, count in emotion_counts.items() if count == 0]\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"MISSING EMOTIONS:\")\n",
        "print(\"=\" * 60)\n",
        "if not missing_emotions:\n",
        "    print(\"All emotions are present at least once.\")\n",
        "else:\n",
        "    print(\"The following emotions are missing:\", missing_emotions)\n",
        "print(\"=\" * 60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdfac45a",
      "metadata": {},
      "source": [
        "# LLM setup for performance comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a2fee1c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Import + API key setup block\n",
        "# -----------------------------\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load variables from the .env file (including OPENAI_API_KEY)\n",
        "load_dotenv()\n",
        "\n",
        "# Set your API key; Ensure that you have created an API key in Open AI and added it to the .env file\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# LangChain core utilities\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# OpenAI Chat models via LangChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Progress bar for batch inference\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9598e214",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "admiration\n",
            "amusement\n",
            "anger\n",
            "annoyance\n",
            "approval\n",
            "caring\n",
            "confusion\n",
            "curiosity\n",
            "desire\n",
            "disappointment\n",
            "disapproval\n",
            "disgust\n",
            "embarassment\n",
            "excitement\n",
            "fear\n",
            "gratitude\n",
            "grief\n",
            "joy\n",
            "love\n",
            "nervousness\n",
            "optimism\n",
            "pride\n",
            "realization\n",
            "relief\n",
            "remorse\n",
            "sadness\n",
            "surprise\n",
            "neutral\n"
          ]
        }
      ],
      "source": [
        "#Create a prompt template to pass to the LLM for inference\n",
        "prompt_template = \"\"\"\n",
        "    You are a highly intelligent emotion classification assistant.\n",
        "    You carefully read a comment, and label it with one or more pre-selected emotion labels to it.\n",
        "    The emotion labels are listed here:\n",
        "    {emotions} \n",
        "    Your output should be just the emotion label that you are applying to the comment, and if you\n",
        "    think there are multple labels then output the labels separated by commas.\n",
        "    The comment to analyze is here: {comment}\n",
        "    \"\"\"\n",
        "#initialize the LangChain string output parser\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "#Initialize the OpenAI model for comparison - let's use gpt-4o-mini \n",
        "gpt4o_mini_llm = ChatOpenAI(temperature = 0.0, model = \"gpt-4o-mini\")  \n",
        "\n",
        "#Initialize LangChain prompt template object \n",
        "emotion_labeling_prompt = ChatPromptTemplate.from_template(prompt_template) \n",
        "\n",
        "#Create an inference chain \n",
        "labeling_chain = ( \n",
        "\n",
        "    {\"comment\" : RunnablePassthrough(), \"emotions\" : RunnablePassthrough()}\n",
        "    | emotion_labeling_prompt\n",
        "    | gpt4o_mini_llm\n",
        "    | output_parser\n",
        ")\n",
        "\n",
        "#create a list of emotions to pass to the LLM in the prompt \n",
        "emotion_labels = []\n",
        "for label in label_index.values():\n",
        "    print(label) \n",
        "    emotion_labels.append(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94470d27",
      "metadata": {},
      "source": [
        "# GPT 4o Mini Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fc62a7dc",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing comments: 100%|██████████| 100/100 [00:52<00:00,  1.91comment/s]\n"
          ]
        }
      ],
      "source": [
        "# The initial gpt-4-t baseline on the first 100 comments\n",
        "def analyze_emotion(comment, emotions):\n",
        "    input_data = {\n",
        "        \"comment\": comment,\n",
        "        \"emotions\": emotion_labels\n",
        "    }\n",
        "    try:\n",
        "        result = labeling_chain.invoke(input_data)\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "gpt4o_mini_emotion_labels = []\n",
        "\n",
        "# Loop through the first 100 comments with progress bar\n",
        "for i in tqdm(range(100), desc=\"Processing comments\", unit=\"comment\"):\n",
        "    comment = comments_df['comment'][i]  # Get the i-th comment\n",
        "    emotion_label = analyze_emotion(comment, emotion_labels)  # Analyze the comment\n",
        "    gpt4o_mini_emotion_labels.append(emotion_label)  # Append the result to the list\n",
        "\n",
        "# Assign the list of emotion labels to a new column in the DataFrame\n",
        "# Assign directly to first 100 rows using .loc to avoid NaN values in remaining rows\n",
        "comments_df.loc[:99, 'gpt4o-mini emotion label'] = gpt4o_mini_emotion_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c68a2b74",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>emotion labels</th>\n",
              "      <th>gpt4o-mini emotion label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>We need more boards and to create a bit more s...</td>\n",
              "      <td>desire, optimism</td>\n",
              "      <td>approval, optimism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Damn youtube and outrage drama is super lucrat...</td>\n",
              "      <td>admiration</td>\n",
              "      <td>anger, annoyance, disapproval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>It might be linked to the trust factor of your...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curiosity, confusion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Demographics? I don’t know anybody under 35 wh...</td>\n",
              "      <td>confusion</td>\n",
              "      <td>confusion, curiosity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Aww... she'll probably come around eventually,...</td>\n",
              "      <td>amusement, approval</td>\n",
              "      <td>admiration, amusement, caring, optimism</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              comment       emotion labels  \\\n",
              "7   We need more boards and to create a bit more s...     desire, optimism   \n",
              "8   Damn youtube and outrage drama is super lucrat...           admiration   \n",
              "9   It might be linked to the trust factor of your...              neutral   \n",
              "10  Demographics? I don’t know anybody under 35 wh...            confusion   \n",
              "11  Aww... she'll probably come around eventually,...  amusement, approval   \n",
              "\n",
              "                   gpt4o-mini emotion label  \n",
              "7                        approval, optimism  \n",
              "8             anger, annoyance, disapproval  \n",
              "9                      curiosity, confusion  \n",
              "10                     confusion, curiosity  \n",
              "11  admiration, amusement, caring, optimism  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Preview the dataset\n",
        "comments_df[7:12]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a069fe26",
      "metadata": {},
      "source": [
        "# Creating training and validation datasets for fine-tuning OpenAI LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "aad05380",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating training dataset: 100%|██████████| 600/600 [00:00<00:00, 29741.21row/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training dataset created successfully!\n",
            "Total examples: 600\n",
            "Output file: training_data.jsonl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a training dataset with 600 examples in JSONL format, which is a pre-requisite for fine-tuning OpenAI models\n",
        "import json\n",
        "\n",
        "# Create emotion labels string for the system message\n",
        "emotion_labels_str = \", \".join(emotion_labels)\n",
        "\n",
        "# Prepare training data from rows 100 to 700\n",
        "training_data = []\n",
        "\n",
        "# Loop through rows 100 to 700 (inclusive)\n",
        "for idx in tqdm(range(100, 700), desc=\"Creating training dataset\", unit=\"row\"):\n",
        "    row = comments_df.iloc[idx]\n",
        "    \n",
        "    # Create the JSON structure for each training example; This chat prompt template for OpenAI LLM inference explicitely mentions the different roles\n",
        "    training_example = {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"You are a highly intelligent emotion classification assistant. You carefully read a comment, and label it with one or more pre-selected emotion labels to it. The emotion labels are listed here: {emotion_labels_str}.Your output should be just the emotion label that you are applying to the comment, and if you think there are multple labels then output the labels separated by commas.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Label the emotion of this comment: {row['comment']}\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": row['emotion labels']\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    training_data.append(training_example)\n",
        "\n",
        "# Write to JSONL file\n",
        "training_data_jsonl = \"training_data.jsonl\"\n",
        "with open(training_data_jsonl, 'w') as f:\n",
        "    for example in training_data:\n",
        "        f.write(json.dumps(example) + '\\n')\n",
        "\n",
        "print(f\"\\nTraining dataset created successfully!\")\n",
        "print(f\"Total examples: {len(training_data)}\")\n",
        "print(f\"Output file: {training_data_jsonl}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4bd8890d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating validation dataset: 100%|██████████| 300/300 [00:00<00:00, 29117.67row/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation dataset created successfully!\n",
            "Total examples: 300\n",
            "Output file: validation_data.jsonl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a validation dataset in JSONL format (required for fine-tuning OpenAI models)\n",
        "\n",
        "# Create emotion labels string for the system message\n",
        "emotion_labels_str = \", \".join(emotion_labels)\n",
        "\n",
        "# Prepare validation data from rows 700 to 1000\n",
        "validation_data = []\n",
        "\n",
        "# Loop through rows 700 to 1000 (inclusive)\n",
        "for idx in tqdm(range(700, 1000), desc=\"Creating validation dataset\", unit=\"row\"):\n",
        "    row = comments_df.iloc[idx]\n",
        "    \n",
        "    # Create the JSON structure for each validation example\n",
        "    validation_example = {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                    f\"You are a highly intelligent emotion classification assistant. \"\n",
        "                    f\"You carefully read a comment and label it with one or more pre-selected emotion labels. \"\n",
        "                    f\"The emotion labels are listed here: {emotion_labels_str}. \"\n",
        "                    f\"Your output should be just the emotion label you apply to the comment, and if there are multiple, \"\n",
        "                    f\"output the labels separated by commas.\"\n",
        "                )\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Label the emotion of this comment: {row['comment']}\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": row['emotion labels']  # ground-truth label\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    validation_data.append(validation_example)\n",
        "\n",
        "# Write to JSONL file\n",
        "validation_data_jsonl = \"validation_data.jsonl\"\n",
        "with open(validation_data_jsonl, 'w') as f:\n",
        "    for example in validation_data:\n",
        "        f.write(json.dumps(example) + '\\n')\n",
        "\n",
        "print(\"\\nValidation dataset created successfully!\")\n",
        "print(f\"Total examples: {len(validation_data)}\")\n",
        "print(f\"Output file: {validation_data_jsonl}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f0ca384",
      "metadata": {},
      "source": [
        "## Fine-Tuned GPT 3.5 Turbo Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "152c8063",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing comments: 100%|██████████| 100/100 [01:29<00:00,  1.12comment/s]\n"
          ]
        }
      ],
      "source": [
        "#Use the same prompt template for the fine-tuned model as we did for the gpt-4o-mini model\n",
        "\n",
        "\"\"\" Now let's use the fine-tuned gpt-3.5-turbo model for inference; \n",
        "You can find the fine-tuned model under OpenAI Platform > Fine-Tuning > Jobs > Job Name > Output Model \"\"\"\n",
        "\n",
        "gpt35t_ft_llm = ChatOpenAI(temperature = 0.0, model = \"ft:gpt-3.5-turbo-1106:personal:llm-finetuning-go-emotions:CcdmOzNu\")  \n",
        "\n",
        "#Initialize LangChain prompt template object \n",
        "emotion_labeling_prompt_gpt35t_ft = ChatPromptTemplate.from_template(prompt_template) \n",
        "\n",
        "#Create an inference chain \n",
        "labeling_chain_gpt35t_ft = ( \n",
        "\n",
        "    {\"comment\" : RunnablePassthrough(), \"emotions\" : RunnablePassthrough()}\n",
        "    | emotion_labeling_prompt_gpt35t_ft\n",
        "    | gpt35t_ft_llm\n",
        "    | output_parser\n",
        ")\n",
        "\n",
        "#create a list of emotions to pass to the LLM in the prompt \n",
        "emotion_labels_gpt35t_ft = []\n",
        "for label in label_index.values():\n",
        "    emotion_labels_gpt35t_ft.append(label) \n",
        "\n",
        "\n",
        "# Function to analyze the emotion of a comment using the fine-tuned gpt-3.5-turbo model\n",
        "def analyze_emotion_gpt35t_ft(comment, emotions):\n",
        "    input_data = {\n",
        "        \"comment\": comment,\n",
        "        \"emotions\": emotion_labels_gpt35t_ft\n",
        "    }\n",
        "    try:\n",
        "        result = labeling_chain_gpt35t_ft.invoke(input_data)\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "gpt35t_ft_emotion_labels = []\n",
        "\n",
        "# Loop through the first 100 comments with progress bar\n",
        "for i in tqdm(range(100), desc=\"Processing comments\", unit=\"comment\"):\n",
        "    comment = comments_df['comment'][i]  # Get the i-th comment\n",
        "    emotion_label = analyze_emotion_gpt35t_ft(comment, emotion_labels_gpt35t_ft)  # Analyze the comment\n",
        "    gpt35t_ft_emotion_labels.append(emotion_label)  # Append the result to the list\n",
        "\n",
        "# Assign the list of emotion labels to a new column in the DataFrame\n",
        "# Assign directly to first 100 rows using .loc to avoid NaN values in remaining rows\n",
        "comments_df.loc[:99, 'gpt3.5t ft emotion label'] = gpt35t_ft_emotion_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "8df5116a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>emotion labels</th>\n",
              "      <th>gpt4o-mini emotion label</th>\n",
              "      <th>gpt3.5t ft emotion label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My favourite food is anything I didn't have to...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>amusement, approval</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if he does off himself, everyone will thin...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>disapproval, sadness, confusion</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
              "      <td>anger</td>\n",
              "      <td>anger, annoyance, disapproval</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To make her feel threatened</td>\n",
              "      <td>fear</td>\n",
              "      <td>fear, disapproval</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dirty Southern Wankers</td>\n",
              "      <td>annoyance</td>\n",
              "      <td>anger, disapproval, disgust</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe...</td>\n",
              "      <td>surprise</td>\n",
              "      <td>anger, annoyance, disapproval</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Yes I heard abt the f bombs! That has to be wh...</td>\n",
              "      <td>gratitude</td>\n",
              "      <td>amusement, excitement, gratitude, nervousness</td>\n",
              "      <td>gratitude</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>We need more boards and to create a bit more s...</td>\n",
              "      <td>desire, optimism</td>\n",
              "      <td>curiosity, optimism</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Damn youtube and outrage drama is super lucrat...</td>\n",
              "      <td>admiration</td>\n",
              "      <td>anger, annoyance, disapproval</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>It might be linked to the trust factor of your...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>curiosity</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment    emotion labels  \\\n",
              "0  My favourite food is anything I didn't have to...           neutral   \n",
              "1  Now if he does off himself, everyone will thin...           neutral   \n",
              "2                     WHY THE FUCK IS BAYLESS ISOING             anger   \n",
              "3                        To make her feel threatened              fear   \n",
              "4                             Dirty Southern Wankers         annoyance   \n",
              "5  OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe...          surprise   \n",
              "6  Yes I heard abt the f bombs! That has to be wh...         gratitude   \n",
              "7  We need more boards and to create a bit more s...  desire, optimism   \n",
              "8  Damn youtube and outrage drama is super lucrat...        admiration   \n",
              "9  It might be linked to the trust factor of your...           neutral   \n",
              "\n",
              "                        gpt4o-mini emotion label gpt3.5t ft emotion label  \n",
              "0                            amusement, approval                  neutral  \n",
              "1                disapproval, sadness, confusion                  neutral  \n",
              "2                  anger, annoyance, disapproval                    anger  \n",
              "3                              fear, disapproval                  neutral  \n",
              "4                    anger, disapproval, disgust                  disgust  \n",
              "5                  anger, annoyance, disapproval                    anger  \n",
              "6  amusement, excitement, gratitude, nervousness                gratitude  \n",
              "7                            curiosity, optimism                  neutral  \n",
              "8                  anger, annoyance, disapproval                    anger  \n",
              "9                                      curiosity                  neutral  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\" Preview the dataset to see a sample of the fine-tuned model's predictions\n",
        "against the ground-truth labels and the gpt-4o-mini model's predictions\"\"\"\n",
        "comments_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a369652a",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llm-finetuning-go-emotions",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
